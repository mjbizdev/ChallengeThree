{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crypto Arbitrage\n",
    "\n",
    "In this Challenge, you'll take on the role of an analyst at a high-tech investment firm. The vice president (VP) of your department is considering arbitrage opportunities in Bitcoin and other cryptocurrencies. As Bitcoin trades on markets across the globe, can you capitalize on simultaneous price dislocations in those markets by using the powers of Pandas?\n",
    "\n",
    "For this assignment, you’ll sort through historical trade data for Bitcoin on two exchanges: Bitstamp and Coinbase. Your task is to apply the three phases of financial analysis to determine if any arbitrage opportunities exist for Bitcoin.\n",
    "\n",
    "This aspect of the Challenge will consist of 3 phases.\n",
    "\n",
    "1. Collect the data.\n",
    "\n",
    "2. Prepare the data.\n",
    "\n",
    "3. Analyze the data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import the required libraries and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#os.path.exists(image_pathname_for_plot_background) #os.path.exists(image_pathname_for_plot_background) ## Collect the Data\n",
    "\n",
    "To collect the data that you’ll need, complete the following steps:\n",
    "\n",
    "Instructions. \n",
    "\n",
    "1. Using the Pandas `read_csv` function and the `Path` module, import the data from `bitstamp.csv` file, and create a DataFrame called `bitstamp`. Set the DatetimeIndex as the Timestamp column, and be sure to parse and format the dates.\n",
    "\n",
    "2. Use the `head` (and/or the `tail`) function to confirm that Pandas properly imported the data.\n",
    "\n",
    "3. Repeat Steps 1 and 2 for `coinbase.csv` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Using the Pandas `read_csv` function and the `Path` module, import the data from `bitstamp.csv` file, and create a DataFrame called `bitstamp`. Set the DatetimeIndex as the Timestamp column, and be sure to parse and format the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_file= r\"..\\Resources\\bitstamp.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mwj\\\\Desktop\\\\FinTech-Workspace\\\\_ChallengeIII_new'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\Resources\\\\bitstamp.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(f_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV file called \"bitstamp.csv\" using the Path module. \n",
    "# The CSV file is located in the Resources folder.\n",
    "# Set the index to the column \"Date\"\n",
    "# Set the parse_dates and infer_datetime_format parameters\n",
    "#csvpath = Path(\"Resources/bitstamp.csv\")\n",
    "bitstamp = pd.read_csv(f_file, parse_dates=True, infer_datetime_format=True)\n",
    "bitstamp = bitstamp.set_index(\"Timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `head` (and/or the `tail`) function to confirm that Pandas properly imported the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>BTC Volume</th>\n",
       "      <th>USD Volume</th>\n",
       "      <th>Weighted Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>13681.04</td>\n",
       "      <td>13681.04</td>\n",
       "      <td>13637.93</td>\n",
       "      <td>$13646.48</td>\n",
       "      <td>3.334553</td>\n",
       "      <td>45482.128785</td>\n",
       "      <td>13639.647479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:01:00</th>\n",
       "      <td>13646.48</td>\n",
       "      <td>13658.75</td>\n",
       "      <td>13610.18</td>\n",
       "      <td>$13658.75</td>\n",
       "      <td>2.663188</td>\n",
       "      <td>36361.390888</td>\n",
       "      <td>13653.332816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:02:00</th>\n",
       "      <td>13616.93</td>\n",
       "      <td>13616.93</td>\n",
       "      <td>13610.06</td>\n",
       "      <td>$13610.22</td>\n",
       "      <td>0.084653</td>\n",
       "      <td>1152.144036</td>\n",
       "      <td>13610.136247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:03:00</th>\n",
       "      <td>13610.27</td>\n",
       "      <td>13639.09</td>\n",
       "      <td>13610.27</td>\n",
       "      <td>$13639.09</td>\n",
       "      <td>7.182986</td>\n",
       "      <td>97856.416478</td>\n",
       "      <td>13623.361128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:04:00</th>\n",
       "      <td>13635.35</td>\n",
       "      <td>13636.35</td>\n",
       "      <td>13620.00</td>\n",
       "      <td>$13620.0</td>\n",
       "      <td>1.069665</td>\n",
       "      <td>14582.660932</td>\n",
       "      <td>13632.923329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:05:00</th>\n",
       "      <td>13620.00</td>\n",
       "      <td>13634.15</td>\n",
       "      <td>13610.00</td>\n",
       "      <td>$13610.0</td>\n",
       "      <td>4.716162</td>\n",
       "      <td>64226.303028</td>\n",
       "      <td>13618.341726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:06:00</th>\n",
       "      <td>13610.00</td>\n",
       "      <td>13650.18</td>\n",
       "      <td>13590.42</td>\n",
       "      <td>$13600.56</td>\n",
       "      <td>26.432759</td>\n",
       "      <td>360108.155630</td>\n",
       "      <td>13623.555198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:07:00</th>\n",
       "      <td>13593.99</td>\n",
       "      <td>13595.41</td>\n",
       "      <td>13566.93</td>\n",
       "      <td>$13580.0</td>\n",
       "      <td>10.674241</td>\n",
       "      <td>144961.611180</td>\n",
       "      <td>13580.507983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:08:00</th>\n",
       "      <td>13580.00</td>\n",
       "      <td>13580.00</td>\n",
       "      <td>13547.59</td>\n",
       "      <td>$13579.0</td>\n",
       "      <td>19.322370</td>\n",
       "      <td>261942.833550</td>\n",
       "      <td>13556.454543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:09:00</th>\n",
       "      <td>13571.28</td>\n",
       "      <td>13571.28</td>\n",
       "      <td>13550.00</td>\n",
       "      <td>$13565.0</td>\n",
       "      <td>0.120942</td>\n",
       "      <td>1641.166577</td>\n",
       "      <td>13569.829917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Open      High       Low      Close  BTC Volume  \\\n",
       "Timestamp                                                                  \n",
       "2018-01-01 00:00:00  13681.04  13681.04  13637.93  $13646.48    3.334553   \n",
       "2018-01-01 00:01:00  13646.48  13658.75  13610.18  $13658.75    2.663188   \n",
       "2018-01-01 00:02:00  13616.93  13616.93  13610.06  $13610.22    0.084653   \n",
       "2018-01-01 00:03:00  13610.27  13639.09  13610.27  $13639.09    7.182986   \n",
       "2018-01-01 00:04:00  13635.35  13636.35  13620.00   $13620.0    1.069665   \n",
       "2018-01-01 00:05:00  13620.00  13634.15  13610.00   $13610.0    4.716162   \n",
       "2018-01-01 00:06:00  13610.00  13650.18  13590.42  $13600.56   26.432759   \n",
       "2018-01-01 00:07:00  13593.99  13595.41  13566.93   $13580.0   10.674241   \n",
       "2018-01-01 00:08:00  13580.00  13580.00  13547.59   $13579.0   19.322370   \n",
       "2018-01-01 00:09:00  13571.28  13571.28  13550.00   $13565.0    0.120942   \n",
       "\n",
       "                        USD Volume  Weighted Price  \n",
       "Timestamp                                           \n",
       "2018-01-01 00:00:00   45482.128785    13639.647479  \n",
       "2018-01-01 00:01:00   36361.390888    13653.332816  \n",
       "2018-01-01 00:02:00    1152.144036    13610.136247  \n",
       "2018-01-01 00:03:00   97856.416478    13623.361128  \n",
       "2018-01-01 00:04:00   14582.660932    13632.923329  \n",
       "2018-01-01 00:05:00   64226.303028    13618.341726  \n",
       "2018-01-01 00:06:00  360108.155630    13623.555198  \n",
       "2018-01-01 00:07:00  144961.611180    13580.507983  \n",
       "2018-01-01 00:08:00  261942.833550    13556.454543  \n",
       "2018-01-01 00:09:00    1641.166577    13569.829917  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the head (and/or tail) function to confirm that the data was imported properly.\n",
    "bitstamp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Repeat Steps 1 and 2 for `coinbase.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV file called \"coinbase.csv\" using the Path module. \n",
    "# The CSV file is located in the Resources folder.\n",
    "# Set the index to the column \"Timestamp\"\n",
    "# Set the parse_dates and infer_datetime_format parameters\n",
    "\n",
    "\n",
    "#bitstamp = pd.read_csv(f_file, parse_dates=True, infer_datetime_format=True)\n",
    "#bitstamp = bitstamp.set_index(\"Timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_file= r'.\\Resources\\bitstamp.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_file2= r\"..\\Resources\\coinbase.csv\"\n",
    "os.path.exists(f_file2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_file2= Path(\"Resources/coinbase.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources\\coinbase.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Resources\\\\coinbase.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23640/464305170.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcsvpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Resources/coinbase.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcoinbase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_file2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcoinbase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoinbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Timestamp\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1218\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    787\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    790\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Resources\\\\coinbase.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "csvpath = Path(\"Resources/coinbase.csv\")\n",
    "print(csvpath)\n",
    "coinbase = pd.read_csv(f_file2, parse_dates=True, infer_datetime_format=True)\n",
    "coinbase = coinbase.set_index(\"Timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the head (and/or tail) function to confirm that the data was imported properly.\n",
    "coinbase.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coinbase.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "To prepare and clean your data for analysis, complete the following steps:\n",
    "\n",
    "1. For the bitstamp DataFrame, replace or drop all `NaN`, or missing, values in the DataFrame.\n",
    "\n",
    "2. Use the `str.replace` function to remove the dollar signs ($) from the values in the Close column.\n",
    "\n",
    "3. Convert the data type of the Close column to a `float`.\n",
    "\n",
    "4. Review the data for duplicated values, and drop them if necessary.\n",
    "\n",
    "5. Repeat Steps 1–4 for the coinbase DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: For the bitstamp DataFrame, replace or drop all `NaN`, or missing, values in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the bitstamp DataFrame, replace or drop all NaNs or missing values in the DataFrame\n",
    "bitstamp = bitstamp.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `str.replace` function to remove the dollar signs ($) from the values in the Close column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the str.replace function to remove the dollar sign, $\n",
    "bitstamp.loc[:,'Close'] = bitstamp['Close'].str.replace(\"$\", \"\",regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Convert the data type of the Close column to a `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Close data type to a float\n",
    "bitstamp['Close'] = bitstamp['Close'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitstamp.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Review the data for duplicated values, and drop them if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the data for duplicate values, and drop them if necessary\n",
    "bitstamp = bitstamp.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Repeat Steps 1–4 for the coinbase DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat Steps 1–4 for the coinbase DataFrame\n",
    "coinbase = coinbase.dropna(how=\"any\")\n",
    "coinbase.loc[:,'Close'] = coinbase[:,'Close'].str.replace(\"$\", \"\")\n",
    "coinbase['Close'] = coinbase[:,'Close'].astype(float)\n",
    "coinbase = coinbase.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Data\n",
    "\n",
    "Your analysis consists of the following tasks: \n",
    "\n",
    "1. Choose the columns of data on which to focus your analysis.\n",
    "\n",
    "2. Get the summary statistics and plot the data.\n",
    "\n",
    "3. Focus your analysis on specific dates.\n",
    "\n",
    "4. Calculate the arbitrage profits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Choose columns of data on which to focus your analysis.\n",
    "\n",
    "Select the data you want to analyze. Use `loc` or `iloc` to select the following columns of data for both the bitstamp and coinbase DataFrames:\n",
    "\n",
    "* Timestamp (index)\n",
    "\n",
    "* Close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loc or iloc to select `Timestamp (the index)` and `Close` from bitstamp DataFrame\n",
    "bitstamp_sliced = bitstamp[['Close']]\n",
    "# Review the first five rows of the DataFrame\n",
    "bitstamp_sliced.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loc or iloc to select `Timestamp (the index)` and `Close` from coinbase DataFrame\n",
    "coinbase_sliced = coinbase [['Close']]\n",
    "\n",
    "# Review the first five rows of the DataFrame\n",
    "coinbase_sliced.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Get summary statistics and plot the data.\n",
    "\n",
    "Sort through the time series data associated with the bitstamp and coinbase DataFrames to identify potential arbitrage opportunities. To do so, complete the following steps:\n",
    "\n",
    "1. Generate the summary statistics for each DataFrame by using the `describe` function.\n",
    "\n",
    "2. For each DataFrame, create a line plot for the full period of time in the dataset. Be sure to tailor the figure size, title, and color to each visualization.\n",
    "\n",
    "3. In one plot, overlay the visualizations that you created in Step 2 for bitstamp and coinbase. Be sure to adjust the legend and title for this new visualization.\n",
    "\n",
    "4. Using the `loc` and `plot` functions, plot the price action of the assets on each exchange for different dates and times. Your goal is to evaluate how the spread between the two exchanges changed across the time period that the datasets define. Did the degree of spread change as time progressed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summary statistics for the bitstamp DataFrame\n",
    "bitstamp_sliced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summary statistics for the coinbase DataFrame\n",
    "coinbase_sliced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot for the bitstamp DataFrame for the full length of time in the dataset \n",
    "# Be sure that the figure size, title, and color are tailored to each visualization\n",
    "bitstamp_sliced.plot(figsize=(8, 6), title = \"Bitstamp\", color='tomato')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a line plot for the coinbase DataFrame for the full length of time in the dataset \n",
    "# Be sure that the figure size, title, and color are tailored to each visualization\n",
    "coinbase_sliced.plot(figsize=(6, 4), title = \"Coinbase\", color='mediumblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the visualizations for the bitstamp and coinbase DataFrames in one plot\n",
    "# The plot should visualize the prices over the full lenth of the dataset\n",
    "# Be sure to include the parameters: legend, figure size, title, and color and label\n",
    "combined_df = bitstamp_sliced.join(coinbase_sliced, lsuffix='_Bitstamp', rsuffix='_Coinbase')\n",
    "new_index = combined_df.index\n",
    "new_index = pd.to_datetime(new_index)\n",
    "combined_df = combined_df.set_index(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.plot(figsize=(14,8), title='Bitstamp & Coinbase', color=['tomato', 'mediumblue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the loc and plot functions, create an overlay plot that visualizes \n",
    "# the price action of both DataFrames for a one month period early in the dataset\n",
    "# Be sure to include the parameters: legend, figure size, title, and color and label\n",
    "new_index = combined_df.index\n",
    "new_index = pd.to_datetime(new_index)\n",
    "combined_df = combined_df.set_index(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the loc and plot functions, create an overlay plot that visualizes \n",
    "# the price action of both DataFrames for a one month period later in the dataset\n",
    "# Be sure to include the parameters: legend, figure size, title, and color and label \n",
    "combined_df[\"03/2018\"].plot(figsize=(14, 8), title='Bitstamp & Coinbase', color=['tomato', 'mediumblue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"01/2018\"].plot(figsize=(14, 8), title='Bitstamp & Coinbase', color=['tomato', 'mediumblue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Based on the visualizations of the different time periods, has the degree of spread change as time progressed?\n",
    "\n",
    "**Answer** Yes, in January we can see higher level of spread change than in March."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Focus Your Analysis on Specific Dates\n",
    "\n",
    "Focus your analysis on specific dates by completing the following steps:\n",
    "\n",
    "1. Select three dates to evaluate for arbitrage profitability. Choose one date that’s early in the dataset, one from the middle of the dataset, and one from the later part of the time period.\n",
    "\n",
    "2. For each of the three dates, generate the summary statistics and then create a box plot. This big-picture view is meant to help you gain a better understanding of the data before you perform your arbitrage calculations. As you compare the data, what conclusions can you draw?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an overlay plot that visualizes the two dataframes over a period of one day early in the dataset. \n",
    "# Be sure that the plots include the parameters `legend`, `figsize`, `title`, `color` and `label` \n",
    "combined_df[\"01/10/2018\"].plot(figsize=(14, 8), title='Bitstamp & Coinbase', color=['tomato', 'mediumblue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using the early date that you have selected, calculate the arbitrage spread \n",
    "# by subtracting the bitstamp lower closing prices from the coinbase higher closing prices\n",
    "arbitrage_spread_early = combined_df.loc['01/10/2018', 'Close_Bitstamp'] - combined_df.loc['01/10/2018', 'Close_Coinbase']\n",
    "\n",
    "# Generate summary statistics for the early DataFrame\n",
    "arbitrage_spread_early = arbitrage_spread_early.to_frame()\n",
    "arbitrage_spread_early.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the arbitrage spread from early in the dataset in a box plot\n",
    "arbitrage_spread_early.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an overlay plot that visualizes the two dataframes over a period of one day from the middle of the dataset. \n",
    "# Be sure that the plots include the parameters `legend`, `figsize`, `title`, `color` and `label` \n",
    "combined_df[\"02/10/2018\"].plot(figsize=(14, 8), title='February 10, 2018', color=['tomato', 'mediumblue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the date in the middle that you have selected, calculate the arbitrage spread \n",
    "# by subtracting the bitstamp lower closing prices from the coinbase higher closing prices\n",
    "arbitrage_spread_middle = combined_df.loc['02/10/2018', 'Close_Bitstamp'] - combined_df.loc['02/10/2018', 'Close_Coinbase']\n",
    "\n",
    "\n",
    "# Generate summary statistics \n",
    "arbitrage_spread_middle = arbitrage_spread_middle.to_frame()\n",
    "arbitrage_spread_middle.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the arbitrage spread from the middle of the dataset in a box plot\n",
    "arbitrage_spread_middle.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an overlay plot that visualizes the two dataframes over a period of one day from late in the dataset. \n",
    "# Be sure that the plots include the parameters `legend`, `figsize`, `title`, `color` and `label` \n",
    "combined_df[\"06//2018\"].plot(figsize=(30, 20), title='March 10', color=['tomato', 'mediumblue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the date from the late that you have selected, calculate the arbitrage spread \n",
    "# by subtracting the bitstamp lower closing prices from the coinbase higher closing prices\n",
    "arbitrage_spread_late = combined_df.loc['03/10/2018', 'Close_Bitstamp'] - combined_df.loc['03/10/2018', 'Close_Coinbase']\n",
    "\n",
    "\n",
    "# Generate summary statistics \n",
    "arbitrage_spread_late = arbitrage_spread_late.to_frame()\n",
    "arbitrage_spread_late.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the arbitrage spread from late in the dataset in a box plot\n",
    "arbitrage_spread_late.plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate the Arbitrage Profits\n",
    "\n",
    "Calculate the potential profits for each date that you selected in the previous section. Your goal is to determine whether arbitrage opportunities still exist in the Bitcoin market. Complete the following steps:\n",
    "\n",
    "1. For each of the three dates, measure the arbitrage spread between the two exchanges by subtracting the lower-priced exchange from the higher-priced one. Then use a conditional statement to generate the summary statistics for each arbitrage_spread DataFrame, where the spread is greater than zero.\n",
    "\n",
    "2. For each of the three dates, calculate the spread returns. To do so, divide the instances that have a positive arbitrage spread (that is, a spread greater than zero) by the price of Bitcoin from the exchange you’re buying on (that is, the lower-priced exchange). Review the resulting DataFrame.\n",
    "\n",
    "3. For each of the three dates, narrow down your trading opportunities even further. To do so, determine the number of times your trades with positive returns exceed the 1% minimum threshold that you need to cover your costs.\n",
    "\n",
    "4. Generate the summary statistics of your spread returns that are greater than 1%. How do the average returns compare among the three dates?\n",
    "\n",
    "5. For each of the three dates, calculate the potential profit, in dollars, per trade. To do so, multiply the spread returns that were greater than 1% by the cost of what was purchased. Make sure to drop any missing values from the resulting DataFrame.\n",
    "\n",
    "6. Generate the summary statistics, and plot the results for each of the three DataFrames.\n",
    "\n",
    "7. Calculate the potential arbitrage profits that you can make on each day. To do so, sum the elements in the profit_per_trade DataFrame.\n",
    "\n",
    "8. Using the `cumsum` function, plot the cumulative sum of each of the three DataFrames. Can you identify any patterns or trends in the profits across the three time periods?\n",
    "\n",
    "(NOTE: The starter code displays only one date. You'll want to do this analysis for two additional dates)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. For each of the three dates, measure the arbitrage spread between the two exchanges by subtracting the lower-priced exchange from the higher-priced one. Then use a conditional statement to generate the summary statistics for each arbitrage_spread DataFrame, where the spread is greater than zero.\n",
    "\n",
    "*NOTE*: For illustration, only one of the three dates is shown in the starter code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index = pd.to_datetime(bitstamp.index)\n",
    "bitstamp = bitstamp.set_index(time_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the date early in the dataset, measure the arbitrage spread between the two exchanges\n",
    "# by subtracting the lower-priced exchange from the higher-priced one\n",
    "arbitrage_spread_early = bitstamp.loc['01/10/2018', 'High'] - bitstamp.loc['01/10/2018', 'Low']\n",
    "arbitrage_spread_middle = bitstamp.loc['02/10/2018', 'High'] - bitstamp.loc['02/10/2018', 'Low']\n",
    "arbitrage_spread_late = bitstamp.loc['03/10/2018', 'High'] - bitstamp.loc['03/10/2018', 'Low']\n",
    "\n",
    "\n",
    "\n",
    "# Use a conditional statement to generate the summary statistics for each arbitrage_spread DataFrame\n",
    "arbitrage_spread_early[arbitrage_spread_early > 0].to_frame().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbitrage_spread_middle[arbitrage_spread_middle > 0].to_frame().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbitrage_spread_late[arbitrage_spread_late > 0].to_frame().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. For each of the three dates, calculate the spread returns. To do so, divide the instances that have a positive arbitrage spread (that is, a spread greater than zero) by the price of Bitcoin from the exchange you’re buying on (that is, the lower-priced exchange). Review the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the date early in the dataset, calculate the spread returns by dividing the instances when the arbitrage spread is positive (> 0) \n",
    "# by the price of Bitcoin from the exchange you are buying on (the lower-priced exchange).\n",
    "\n",
    "# Review the spread return DataFrame\n",
    "bitstamp['arbitrage spread'] = bitstamp['High'] - bitstamp['Low']\n",
    "bitstamp['spread return'] = bitstamp['arbitrage spread'] / bitstamp['Low']\n",
    "\n",
    "spread_return_early = bitstamp.loc['01/10/2018'].loc[bitstamp['arbitrage spread'] > 0, 'spread return']\n",
    "spread_return_early\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitstamp['arbitrage spread'] = bitstamp['High'] - bitstamp['Low']\n",
    "bitstamp['spread return'] = bitstamp['arbitrage spread'] / bitstamp['Low']\n",
    "\n",
    "spread_return_middle = bitstamp['02/10/2018'].loc[bitstamp['arbitrage spread'] > 0, 'spread return']\n",
    "spread_return_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitstamp['arbitrage spread'] = bitstamp['High'] - bitstamp['Low']\n",
    "bitstamp['spread return'] = bitstamp['arbitrage spread'] / bitstamp['Low']\n",
    "\n",
    "spread_return_late = bitstamp.loc['03/10/2018'].loc[bitstamp['arbitrage spread'] > 0, 'spread return']\n",
    "spread_return_late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. For each of the three dates, narrow down your trading opportunities even further. To do so, determine the number of times your trades with positive returns exceed the 1% minimum threshold that you need to cover your costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the date early in the dataset, determine the number of times your trades with positive returns \n",
    "# exceed the 1% minimum threshold (.01) that you need to cover your costs\n",
    "profitable_trades_early = spread_return_early[spread_return_early > 0.01]\n",
    "profitable_trades_middle = spread_return_middle[spread_return_middle > 0.01]\n",
    "profitable_trades_late = spread_return_late[spread_return_late > 0.01]\n",
    "\n",
    "\n",
    "# Review the first five profitable trades\n",
    "profitable_trades_early.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Generate the summary statistics of your spread returns that are greater than 1%. How do the average returns compare among the three dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the date early in the dataset, generate the summary statistics for the profitable trades\n",
    "# or you trades where the spread returns are are greater than 1%\n",
    "profitable_trades_early.to_frame().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitable_trades_middle.to_frame().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitable_trades_late.to_frame().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. For each of the three dates, calculate the potential profit, in dollars, per trade. To do so, multiply the spread returns that were greater than 1% by the cost of what was purchased. Make sure to drop any missing values from the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the date early in the dataset, calculate the potential profit per trade in dollars \n",
    "# Multiply the profitable trades by the cost of the Bitcoin that was purchased\n",
    "profit_early = spread_return_early * bitstamp['BTC Volume']\n",
    "\n",
    "# Drop any missing values from the profit DataFrame\n",
    "profit_per_trade_early = profit_early.dropna()\n",
    "\n",
    "# View the early profit DataFrame\n",
    "profit_per_trade_early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_middle = spread_return_middle * bitstamp['BTC Volume']\n",
    "profit_per_trade_middle = profit_middle.dropna()\n",
    "profit_per_trade_middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_late = spread_return_late * bitstamp['BTC Volume']\n",
    "profit_per_trade_late = profit_late.dropna()\n",
    "profit_per_trade_late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Generate the summary statistics, and plot the results for each of the three DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summary statistics for the early profit per trade DataFrame\n",
    "profit_per_trade_early.to_frame().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the early profit per trade DataFrame\n",
    "profit_per_trade_early.plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_per_trade_middle.to_frame().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_per_trade_middle.plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_per_trade_late.to_frame().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_per_trade_late.plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Calculate the potential arbitrage profits that you can make on each day. To do so, sum the elements in the profit_per_trade DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the potential profits for the early profit per trade DataFrame\n",
    "profit_per_trade_early.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profit_per_trade_middle.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_per_trade_late.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Using the `cumsum` function, plot the cumulative sum of each of the three DataFrames. Can you identify any patterns or trends in the profits across the three time periods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the cumsum function to calculate the cumulative profits over time for the early profit per trade DataFrame\n",
    "cumulative_profit_early = profit_per_trade_early.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cumulative sum of profits for the early profit per trade DataFrame\n",
    "cumulative_profit_early.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_profit_middle = profit_per_trade_middle.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_profit_middle.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_profit_late = profit_per_trade_late.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_profit_late.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** After reviewing the profit information across each date from the different time periods, can you identify any patterns or trends?\n",
    "    \n",
    "**Answer:** From January to March, the profit income from buying Bitcoin decreased by more than 2 time. The best month for trade was January out of these 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
